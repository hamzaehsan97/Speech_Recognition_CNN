{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from keras.utils import to_categorical\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR To use wandb on Windows, you need to run the command \"wandb run python <your_train_script>.py\"\n",
      "Saving vectors of label - 'bed': 100%|██████████| 1713/1713 [00:10<00:00, 159.18it/s]\n",
      "Saving vectors of label - 'cat': 100%|██████████| 1733/1733 [00:10<00:00, 162.73it/s]\n",
      "Saving vectors of label - 'happy': 100%|██████████| 1742/1742 [00:11<00:00, 148.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0726 15:45:39.599763 14668 deprecation_wrapper.py:119] From C:\\Users\\HamzaEhsan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 15:45:39.636664 14668 deprecation_wrapper.py:119] From C:\\Users\\HamzaEhsan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0726 15:45:39.660600 14668 deprecation_wrapper.py:119] From C:\\Users\\HamzaEhsan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0726 15:45:39.684535 14668 deprecation_wrapper.py:119] From C:\\Users\\HamzaEhsan\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0726 15:45:39.709469 14668 deprecation_wrapper.py:119] From C:\\Users\\HamzaEhsan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "wandb: ERROR To use wandb on Windows, you need to run the command \"wandb run python <your_train_script>.py\"\n",
      "wandb: ERROR wandb.init hasn't been called, can't configure run\n",
      "W0726 15:45:39.837127 14668 deprecation.py:323] From C:\\Users\\HamzaEhsan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0726 15:45:39.879015 14668 deprecation_wrapper.py:119] From C:\\Users\\HamzaEhsan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3112 samples, validate on 2076 samples\n",
      "Epoch 1/50\n",
      "3112/3112 [==============================] - 0s 121us/step - loss: 10.1951 - acc: 0.3438 - val_loss: 8.6630 - val_acc: 0.4128\n",
      "Epoch 2/50\n",
      "3112/3112 [==============================] - 0s 52us/step - loss: 7.2260 - acc: 0.4846 - val_loss: 6.1950 - val_acc: 0.5530\n",
      "Epoch 3/50\n",
      "3112/3112 [==============================] - 0s 44us/step - loss: 5.2109 - acc: 0.6179 - val_loss: 4.7010 - val_acc: 0.6460\n",
      "Epoch 4/50\n",
      "3112/3112 [==============================] - 0s 39us/step - loss: 4.3191 - acc: 0.6751 - val_loss: 4.2899 - val_acc: 0.6811\n",
      "Epoch 5/50\n",
      "3112/3112 [==============================] - 0s 38us/step - loss: 3.8207 - acc: 0.7098 - val_loss: 3.7651 - val_acc: 0.7110\n",
      "Epoch 6/50\n",
      "3112/3112 [==============================] - 0s 52us/step - loss: 3.4373 - acc: 0.7359 - val_loss: 3.4883 - val_acc: 0.7254\n",
      "Epoch 7/50\n",
      "3112/3112 [==============================] - 0s 44us/step - loss: 3.2361 - acc: 0.7471 - val_loss: 3.2556 - val_acc: 0.7442\n",
      "Epoch 8/50\n",
      "3112/3112 [==============================] - 0s 41us/step - loss: 2.9761 - acc: 0.7629 - val_loss: 3.1712 - val_acc: 0.7476\n",
      "Epoch 9/50\n",
      "3112/3112 [==============================] - 0s 43us/step - loss: 2.8020 - acc: 0.7773 - val_loss: 3.1971 - val_acc: 0.7529\n",
      "Epoch 10/50\n",
      "3112/3112 [==============================] - 0s 42us/step - loss: 2.6386 - acc: 0.7863 - val_loss: 2.8718 - val_acc: 0.7741\n",
      "Epoch 11/50\n",
      "3112/3112 [==============================] - 0s 40us/step - loss: 2.4749 - acc: 0.7988 - val_loss: 2.9524 - val_acc: 0.7620\n",
      "Epoch 12/50\n",
      "3112/3112 [==============================] - 0s 48us/step - loss: 2.3403 - acc: 0.8046 - val_loss: 3.0164 - val_acc: 0.7558\n",
      "Epoch 13/50\n",
      "3112/3112 [==============================] - 0s 37us/step - loss: 2.2949 - acc: 0.8078 - val_loss: 2.6616 - val_acc: 0.7823\n",
      "Epoch 14/50\n",
      "3112/3112 [==============================] - 0s 38us/step - loss: 2.0495 - acc: 0.8249 - val_loss: 2.6290 - val_acc: 0.7876\n",
      "Epoch 15/50\n",
      "3112/3112 [==============================] - 0s 50us/step - loss: 2.0928 - acc: 0.8204 - val_loss: 2.5281 - val_acc: 0.7914\n",
      "Epoch 16/50\n",
      "3112/3112 [==============================] - 0s 45us/step - loss: 1.9793 - acc: 0.8303 - val_loss: 2.5534 - val_acc: 0.7842\n",
      "Epoch 17/50\n",
      "3112/3112 [==============================] - 0s 46us/step - loss: 1.9959 - acc: 0.8284 - val_loss: 2.5547 - val_acc: 0.7876\n",
      "Epoch 18/50\n",
      "3112/3112 [==============================] - 0s 37us/step - loss: 1.9564 - acc: 0.8371 - val_loss: 2.5585 - val_acc: 0.7842\n",
      "Epoch 19/50\n",
      "3112/3112 [==============================] - 0s 38us/step - loss: 1.8512 - acc: 0.8409 - val_loss: 2.5233 - val_acc: 0.7909\n",
      "Epoch 20/50\n",
      "3112/3112 [==============================] - 0s 40us/step - loss: 1.8270 - acc: 0.8464 - val_loss: 2.5807 - val_acc: 0.7828\n",
      "Epoch 21/50\n",
      "3112/3112 [==============================] - 0s 41us/step - loss: 1.7947 - acc: 0.8429 - val_loss: 2.5224 - val_acc: 0.7924\n",
      "Epoch 22/50\n",
      "3112/3112 [==============================] - 0s 34us/step - loss: 1.8313 - acc: 0.8435 - val_loss: 2.5637 - val_acc: 0.7885\n",
      "Epoch 23/50\n",
      "3112/3112 [==============================] - 0s 47us/step - loss: 1.7956 - acc: 0.8442 - val_loss: 2.5437 - val_acc: 0.7856\n",
      "Epoch 24/50\n",
      "3112/3112 [==============================] - 0s 54us/step - loss: 1.7708 - acc: 0.8442 - val_loss: 2.5936 - val_acc: 0.7847\n",
      "Epoch 25/50\n",
      "3112/3112 [==============================] - 0s 49us/step - loss: 1.7986 - acc: 0.8429 - val_loss: 2.4698 - val_acc: 0.7958\n",
      "Epoch 26/50\n",
      "3112/3112 [==============================] - 0s 49us/step - loss: 1.7432 - acc: 0.8393 - val_loss: 2.6164 - val_acc: 0.7784\n",
      "Epoch 27/50\n",
      "3112/3112 [==============================] - 0s 92us/step - loss: 1.7194 - acc: 0.8461 - val_loss: 2.4832 - val_acc: 0.7856\n",
      "Epoch 28/50\n",
      "3112/3112 [==============================] - 0s 106us/step - loss: 1.7448 - acc: 0.8458 - val_loss: 2.4768 - val_acc: 0.7967\n",
      "Epoch 29/50\n",
      "3112/3112 [==============================] - 0s 54us/step - loss: 1.6765 - acc: 0.8515 - val_loss: 2.6216 - val_acc: 0.7746\n",
      "Epoch 30/50\n",
      "3112/3112 [==============================] - 0s 57us/step - loss: 1.7580 - acc: 0.8419 - val_loss: 2.5063 - val_acc: 0.7881\n",
      "Epoch 31/50\n",
      "3112/3112 [==============================] - 0s 53us/step - loss: 1.7327 - acc: 0.8416 - val_loss: 2.5108 - val_acc: 0.7876\n",
      "Epoch 32/50\n",
      "3112/3112 [==============================] - 0s 40us/step - loss: 1.6828 - acc: 0.8442 - val_loss: 2.5481 - val_acc: 0.7799\n",
      "Epoch 33/50\n",
      "3112/3112 [==============================] - 0s 42us/step - loss: 1.6670 - acc: 0.8490 - val_loss: 2.5083 - val_acc: 0.7861\n",
      "Epoch 34/50\n",
      "3112/3112 [==============================] - 0s 45us/step - loss: 1.6517 - acc: 0.8541 - val_loss: 2.4312 - val_acc: 0.7962\n",
      "Epoch 35/50\n",
      "3112/3112 [==============================] - 0s 48us/step - loss: 1.6294 - acc: 0.8467 - val_loss: 2.5484 - val_acc: 0.7842\n",
      "Epoch 36/50\n",
      "3112/3112 [==============================] - 0s 47us/step - loss: 1.6249 - acc: 0.8515 - val_loss: 2.6770 - val_acc: 0.7760\n",
      "Epoch 37/50\n",
      "3112/3112 [==============================] - 0s 54us/step - loss: 1.6749 - acc: 0.8531 - val_loss: 2.5354 - val_acc: 0.7813\n",
      "Epoch 38/50\n",
      "3112/3112 [==============================] - 0s 45us/step - loss: 1.5836 - acc: 0.8522 - val_loss: 2.3688 - val_acc: 0.7900\n",
      "Epoch 39/50\n",
      "3112/3112 [==============================] - 0s 46us/step - loss: 1.5860 - acc: 0.8509 - val_loss: 2.4133 - val_acc: 0.7895\n",
      "Epoch 40/50\n",
      "3112/3112 [==============================] - 0s 44us/step - loss: 1.6401 - acc: 0.8490 - val_loss: 2.4535 - val_acc: 0.7856\n",
      "Epoch 41/50\n",
      "3112/3112 [==============================] - 0s 46us/step - loss: 1.5892 - acc: 0.8544 - val_loss: 2.4179 - val_acc: 0.7890\n",
      "Epoch 42/50\n",
      "3112/3112 [==============================] - 0s 45us/step - loss: 1.5042 - acc: 0.8567 - val_loss: 2.4516 - val_acc: 0.7823\n",
      "Epoch 43/50\n",
      "3112/3112 [==============================] - 0s 47us/step - loss: 1.5132 - acc: 0.8557 - val_loss: 2.4428 - val_acc: 0.7856\n",
      "Epoch 44/50\n",
      "3112/3112 [==============================] - 0s 45us/step - loss: 1.4625 - acc: 0.8638 - val_loss: 2.4048 - val_acc: 0.7900\n",
      "Epoch 45/50\n",
      "3112/3112 [==============================] - 0s 51us/step - loss: 1.5005 - acc: 0.8580 - val_loss: 2.5090 - val_acc: 0.7808\n",
      "Epoch 46/50\n",
      "3112/3112 [==============================] - 0s 59us/step - loss: 1.5721 - acc: 0.8483 - val_loss: 2.3367 - val_acc: 0.7909\n",
      "Epoch 47/50\n",
      "3112/3112 [==============================] - 0s 62us/step - loss: 1.5660 - acc: 0.8515 - val_loss: 2.3496 - val_acc: 0.7900\n",
      "Epoch 48/50\n",
      "3112/3112 [==============================] - 0s 44us/step - loss: 1.4983 - acc: 0.8583 - val_loss: 2.3814 - val_acc: 0.7938\n",
      "Epoch 49/50\n",
      "3112/3112 [==============================] - 0s 38us/step - loss: 1.4915 - acc: 0.8583 - val_loss: 2.4627 - val_acc: 0.7856\n",
      "Epoch 50/50\n",
      "3112/3112 [==============================] - 0s 40us/step - loss: 1.5251 - acc: 0.8528 - val_loss: 2.4817 - val_acc: 0.7808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27b72fd0e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "config.max_len = 11\n",
    "config.buckets = 20\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=config.max_len, n_mfcc=config.buckets)\n",
    "\n",
    "labels=[\"bed\", \"happy\", \"cat\"]\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "# # Feature dimension\n",
    "channels = 1\n",
    "config.epochs = 50\n",
    "config.batch_size = 100\n",
    "\n",
    "num_classes = 3\n",
    "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len, channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], config.buckets, config.max_len, channels)\n",
    "plt.imshow(X_train[100, :, :, 0])\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len)\n",
    "X_test = X_test.reshape(X_test.shape[0], config.buckets, config.max_len)\n",
    "\n",
    "\n",
    "x_final_vector = []\n",
    "x_final_vector_vector = []\n",
    "x_final_vector = wav2mfcc('output.wav')\n",
    "x_final_vector_vector.append(x_final_vector)\n",
    "x_final = np.array(x_final_vector_vector)\n",
    "# print predict sample shape\n",
    "print(x_final.shape)\n",
    "# x_final = x_final.reshape(config.buckets, config.max_len) \n",
    "\n",
    "model = Sequential()\n",
    "input_shape = X_train[0].shape\n",
    "# print predict sample shape\n",
    "print(input_shape)\n",
    "\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "wandb.init()\n",
    "model.fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_test, y_test_hot), callbacks=[WandbCallback(data_type=\"image\", labels=labels)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "y_final_oneHotEncoded= model.predict_classes(x_final, batch_size=1, verbose=0)\n",
    "y_final_num = argmax(y_final_oneHotEncoded)\n",
    "print(y_final_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 220)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 663       \n",
      "=================================================================\n",
      "Total params: 663\n",
      "Trainable params: 663\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_model(model, to_file=\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4d07b5afe9f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"model.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         raise ImportError(\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[1;34m'Failed to import `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;34m'Please install `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
